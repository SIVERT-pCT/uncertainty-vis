{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_angle = 179\n",
    "num_offset = 1\n",
    "num_spotx = 130\n",
    "chord_length = 'map'\n",
    "RSP_shape = [130, 130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = sparse.load_npz(f'../../Data/simple_pCT/MLP/MLP_angles{num_angle}_offset{num_offset}_spotx{num_spotx}_{chord_length}_{RSP_shape[0]}_{RSP_shape[1]}.npz')\n",
    "wepl = np.load(f'../../Data/simple_pCT/WEPL/WEPL_angles{num_angle}_offset{num_offset}_spotx{num_spotx}_{chord_length}_{RSP_shape[0]}_{RSP_shape[1]}.npy').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = np.zeros(RSP_shape, dtype='bool')\n",
    "for i in range(RSP_shape[0]):\n",
    "    for j in range(RSP_shape[1]):\n",
    "        # a circle is used as a valid volume\n",
    "        vec = np.array([i, j])\n",
    "        center = np.array(RSP_shape) // 2 \n",
    "        \n",
    "        obj[i,j] = True if (i - center[0])**2 / center[0]**2 + (j - center[1])**2 / center[1]**2 <= 1 else False\n",
    "\n",
    "obj = obj.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_norm = sparse.linalg.norm(mlp, axis=1)**2\n",
    "valid = A_norm > 1e-9\n",
    "A_norm = A_norm[valid].astype(np.float32)\n",
    "\n",
    "S_array = np.array([mlp[:,i].count_nonzero() for i in range(mlp.shape[1])])\n",
    "S_array[ S_array <= 0 ] = 1\n",
    "S_array = 1 / S_array\n",
    "S_array = S_array.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (23101) must match the size of tensor b (390406900) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m hist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2000\u001b[39m):\n\u001b[0;32m---> 33\u001b[0m     x, res \u001b[38;5;241m=\u001b[39m \u001b[43mdropSetp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#ft_jacobian = torch.func.jacrev(dropSetp, argnums=2)(x, A, b, S, lamb)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[70], line 17\u001b[0m, in \u001b[0;36mdropSetp\u001b[0;34m(x, A, b, S)\u001b[0m\n\u001b[1;32m     13\u001b[0m Ax \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreshape(torch\u001b[38;5;241m.\u001b[39msparse\u001b[38;5;241m.\u001b[39mmm(A, x), (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# print('Ax:', Ax.shape)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# print('b:', b.shape)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m residuals \u001b[38;5;241m=\u001b[39m \u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mAx\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print('residuals:', residuals.shape)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m factor \u001b[38;5;241m=\u001b[39m residuals \u001b[38;5;241m/\u001b[39m A_norm\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (23101) must match the size of tensor b (390406900) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "x = torch.rand((np.prod(RSP_shape), 1), dtype=torch.float32)\n",
    "\n",
    "lamb = 0.5\n",
    "coo = mlp[valid,:].tocoo()\n",
    "indices = np.mat([coo.row, coo.col])\n",
    "A = torch.sparse_coo_tensor(indices, coo.data.astype(np.float32), coo.shape)\n",
    "b = torch.tensor(wepl[valid].astype(np.float32))\n",
    "S = torch.tensor(S_array * lamb)\n",
    "\n",
    "def dropSetp(x, A, b, S):\n",
    "\n",
    "    # print('S:', S.shape)\n",
    "    Ax = torch.reshape(torch.sparse.mm(A, x), (-1,))\n",
    "    # print('Ax:', Ax.shape)\n",
    "    # print('b:', b.shape)\n",
    "\n",
    "    residuals = b - Ax\n",
    "    # print('residuals:', residuals.shape)\n",
    "    factor = residuals / A_norm\n",
    "    # print('factor:', factor.shape)\n",
    "    temp1 = torch.transpose(A, 0, 1)\n",
    "    # print('temp1:', temp1.shape)\n",
    "    temp2 = torch.matmul(temp1, factor)\n",
    "    # print('temp2:', temp2.shape)\n",
    "    temp3 = S * temp2\n",
    "    # print('temp3:', temp3.shape)\n",
    "\n",
    "    return x + temp3, residuals\n",
    "\n",
    "hist = []\n",
    "for iter in range(2000):\n",
    "    x, res = dropSetp(x, A, b, S)\n",
    "\n",
    "#ft_jacobian = torch.func.jacrev(dropSetp, argnums=2)(x, A, b, S, lamb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
